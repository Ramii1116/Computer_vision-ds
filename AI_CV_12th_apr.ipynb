{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c137f5-3d57-4274-920b-a3187097d5db",
   "metadata": {},
   "source": [
    "#### pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93207876-1487-46bc-8862-994dc3694fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python-headless  # For a smaller installation without GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc884c4a-6160-478e-b355-903ddf17c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-contrib-python    # Includes extra modules like SIFT, SURF, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397daea9-2ad0-4d14-bcc9-9f12ddf8d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as pd\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f49cf6-1240-402d-87f3-960ab86e6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"Blank.jpg\", 1)  # Load in color mode\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if img is None:\n",
    "    print(\"Error: Image not found or could not be loaded\")\n",
    "else:\n",
    "    # Resize the image to the specified dimensions (width, height)\n",
    "    resized = cv2.resize(img, (350, 700))\n",
    "\n",
    "    # Convert the resized image to grayscale\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resized color image in a window named \"raj gadu\"\n",
    "    cv2.imshow(\"raj gadu\", resized)\n",
    "\n",
    "    # Optionally, display the grayscale image in a separate window\n",
    "    cv2.imshow(\"raj gadu - grayscale\", gray)\n",
    "\n",
    "    # Wait for a key press (indefinitely)\n",
    "    cv2.waitKey(0)  # Change to a number (e.g., 100) for a timed wait\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0710b-7685-4ee5-839d-33d6ff392c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47def8-7c1b-423b-a66f-3ef341ad5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96a69-785c-4d7f-8873-33e2a4361b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f75c93-6ba8-4750-a08b-2c098d3ff007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing the image...\n",
    "img = cv2.imread(\"modi.jpg\",1)\n",
    "resized = cv2.resize(img,(498,800))  # width and height\n",
    "\n",
    "# converting color to gray\n",
    "gray = cv2.cvtColor(resized,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# diplaying \n",
    "cv2.imshow(\"modi\",gray) # tab name is modi, and modi resized gray img\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad6b69-f198-4582-9372-4edcd0488792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the image\n",
    "cv2.imwrite(\"modi_b.jpg\",gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b21f74-4291-4c39-88d8-66f00437abbf",
   "metadata": {},
   "source": [
    "# computer vision..\n",
    "- object detection as per ur requirements...\n",
    "- if wnt to detect human face/mobile it will detect as like the image object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32dff59-2256-446a-a68a-a546964c4ee0",
   "metadata": {},
   "source": [
    "# **Frontal Face Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ccbcd0-a4b1-47d2-99c9-5a8bb261d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError(\" face file problem\")\n",
    "\n",
    "# Read an image\n",
    "img = cv2.imread('Blank.jpg',1)\n",
    "img = cv2.resize(img,(400,700))\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the grayscale image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)  # BGR color format: (blue, green, red)\n",
    "\n",
    "# Display the image with detected faces\n",
    "cv2.imshow('Detected Faces',img)\n",
    "cv2.waitKey(0)  # Wait for any key press\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354bbdd-d8c6-4d60-8867-98f3f5d6bcd5",
   "metadata": {},
   "source": [
    "# **Face and Eye Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307f168-1cca-4a83-81a5-a640c9c58452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the cascade classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "#face_classifier = cv2.CascadeClassifier(\"Haarcascades/haarcascade_frontalface_default.xml\")\n",
    "#eye_classifier = cv2.CascadeClassifier(\"Haarcascade/haarcascade_eye.xml\")\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError(\" face file problem\")\n",
    "if eye_cascade.empty():\n",
    "    raise IOError(\" eye file problem\")\n",
    "\n",
    "# Read an image\n",
    "img = cv2.imread('Blank.jpg',1)\n",
    "\n",
    "img = cv2.resize(img,(400,700))\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the grayscale image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Iterate over detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    # Draw rectangle around the face on the original image (optional)\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Extract the region of interest (ROI) from grayscale image\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    \n",
    "    # Detect eyes in the ROI of the face\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    \n",
    "    # Iterate over detected eyes and draw rectangles around them\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# Display the image with detected faces and eyes\n",
    "cv2.imshow('Face and Eye Detection', img)\n",
    "cv2.waitKey(0)  # Wait for any key press\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d370ac0-0a4e-4c50-8f79-45db75039e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load pre-trained face and eye cascade classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError(\" face file problem\")\n",
    "if eye_cascade.empty():\n",
    "    raise IOError(\" eye file problem\")\n",
    "\n",
    "# Function to detect faces and eyes\n",
    "def detect_faces_and_eyes(image_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    # Read an image\n",
    "    img = cv2.resize(img,(400,700))\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"No faces detected\")\n",
    "        return\n",
    "    \n",
    "    # Iterate over detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Region of interest (ROI) for eyes in the detected face\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        # Detect eyes in the face\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        # If no eyes detected in the face\n",
    "        if len(eyes) == 0:\n",
    "            print(\"Eyes not detected in this face\")\n",
    "        \n",
    "        # Draw rectangles around eyes\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (255,0, 0), 2)\n",
    "    \n",
    "    # Display the image with detections\n",
    "    cv2.imshow('Face and Eyes Detection', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = 'raj.jpg'\n",
    "detect_faces_and_eyes(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612638a-f04b-43e0-9b30-38af039d8433",
   "metadata": {},
   "source": [
    "# Capture a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825ffc9-1b41-4e79-a5ad-6c276eb1dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing a video with webcam..black and white video\n",
    "import cv2\n",
    "video = cv2.VideoCapture(0)     #0 webcam or write the path of video\n",
    "\n",
    "while True:\n",
    "    num,frame = video.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"video\",gray)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab309e5-99e4-4dd7-86fd-80312e4fd5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing a video with webcam..color video\n",
    "\n",
    "import cv2\n",
    "video = cv2.VideoCapture(0)     #0 webcam or write the path of video\n",
    "\n",
    "while True:\n",
    "    num,frame = video.read()\n",
    "    #gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"video\",frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad9bd0e-2ce9-4e7c-9774-c169207bc916",
   "metadata": {},
   "source": [
    "# face and eye detection with video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8fa1e-154a-4e8e-8ef7-5987d206e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade face and eye classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "if face_cascade.empty():\n",
    "    raise IOError(\" face_cascade file problem\")\n",
    "if eye_cascade.empty():\n",
    "    raise IOError(\" eye_cascade file problem\")\n",
    "\n",
    "# Function to detect faces and eyes\n",
    "def detect(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "# Initialize webcam capture\n",
    "cap = cv2.VideoCapture(0)  # 0 represents the default camera\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert frame to grayscale for face and eye detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces and eyes\n",
    "    canvas = detect(gray, frame)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face and Eyes Detection', canvas)\n",
    "    \n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588defe1-8555-4f97-8906-04940e7ab66e",
   "metadata": {},
   "source": [
    "# pedestrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd5524-a91d-42e1-af1e-35d3d1584477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade face and eye classifiers\n",
    "fullbody_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "\n",
    "if fullbody_cascade.empty():\n",
    "    raise IOError(\" eye file problem\")\n",
    "\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"fullbody.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    check,frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "    bodies = fullbody_cascade.detectMultiScale(gray,1,5)\n",
    "\n",
    "    # Extract bonding boxes for any body identified\n",
    "    for (x,y,w,h) in bodies:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h), (55,10,155), 1)\n",
    "        cv2.imshow(\"pedestrials\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6fa33-0956-4b54-b3e8-7eeb9e4b2b71",
   "metadata": {},
   "source": [
    "# Only Eyes detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace39b6-94a9-48bb-9feb-e9206037289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar cascade classifier for eyes\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('blank.jpg')\n",
    "resized = cv2.resize(img,(400,700))\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect eyes in the image\n",
    "eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Draw rectangles around the eyes\n",
    "for (ex, ey, ew, eh) in eyes:\n",
    "    cv2.rectangle(resized, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with the detected eyes\n",
    "cv2.imshow('Detected Eyes', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff435fa6-4bf2-4974-b9d6-bc3913c2cfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf37ee-564e-4bb9-affe-53b6645e443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "car_cascade = cv2.CascadeClassifier(\"cars.xml\")\n",
    "\n",
    "if car_cascade.empty():\n",
    "    raise IOError(\" cars file problem\")\n",
    "    \n",
    "# Path to the car cascade classifier (download from OpenCV website)\n",
    "\n",
    "# Initialize video capture (replace 0 with video file path for video processing)\n",
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "while True:\n",
    "  # Read a frame from the video capture\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "  # Convert frame to grayscale (Haar cascade classifiers work better in grayscale)\n",
    "  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Load the car cascade classifier\n",
    "\n",
    "  # Detect cars in the frame\n",
    "  cars = car_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "  # Draw rectangles around detected cars\n",
    "  for (x, y, w, h) in cars:\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "  # Display the resulting frame\n",
    "    cv2.imshow('Car Detection', frame)\n",
    "\n",
    "  # Exit if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c1ae6-dc1c-4ef7-a16f-348fca9f2f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
